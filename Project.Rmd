---
title: "Project - STAT 151A"
author: "Aditya Jhanwar"
date: "12/8/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "")
setwd("~/151A/Project/")
rm(list=ls())
library(tidyverse)
```

```{r load_data}
load(url("http://www.stat.berkeley.edu/users/nolan/data/baseball2012.rda"))
baseball = as_tibble(baseball)
```

# Data Exploration and Feature Creation 

### 1)

The first step is to clean the `baseball` data by removing unecessary explanatory variables and entries missing a `salary (observed Yi)` value.

```{r cleaning.data}
baseball = baseball %>% select(-c("ID", "yearID", "teamID", "lgID", "nameFirst", "nameLast", "G_batting")) # remove unecessary variables
baseball = baseball %>% drop_na(salary) # remove units with no salary values
```

Next, I followed the author's process in creating new features as decribed in the textbook.

```{r derived.vars}
baseball = baseball %>% mutate(AVG = CH/CAB,
                               OBP = 100*(CH + CBB)/(CAB + CBB),
                               CAB.avg  = CAB/years,
                               CH.avg   = CH/years,
                               CHR.avg  = CHR/years,
                               CR.avg   = CR/years,
                               CRBI.avg = CRBI/years)
```

Finally, I cleaned the `Position` and `Years` explanatory variables through reimpementing them as dummy variables.

According to Fox's description of his analysis, he mentions **middle infielders** as players who consistently played second base or shortstop so I classified all individuals with either position as such. 

```{r dummy.vars.position}
new.pos = c()
MI = c("12", "1S", "23", "2B", "2S", "3S", "O2", "SS")
C  = c("C", "C1", "OC")
CF = c("CF")
  
# Assign new factor assignment for MI (middle infielders), C (catcher), CF (center field), and O (other)
for (i in baseball$POS){
  if      (i %in% MI) { new.pos = c(new.pos, "MI") }
  else if (i %in% C)  { new.pos = c(new.pos, "C")  }
  else if (i %in% CF) { new.pos = c(new.pos, "CF") }
  else                { new.pos = c(new.pos, "O")  }
}

baseball$POS = relevel(factor(new.pos), "O")
```

```{r dummy.vars.salary}
new.years = c()
neg.cont  = 6
neg.sal   = 3

for (i in baseball$years){
  if      (i >= neg.cont) { new.years = c(new.years, "neg.contract") }
  else if (i >= neg.sal)  { new.years = c(new.years, "neg.salary")   }
  else                    { new.years = c(new.years, "other")        }
}

baseball$years = relevel(factor(new.years), "other")
```

```{r}
lm.fit = lm(salary ~ ., data = baseball)
new.baseball = as_tibble(model.matrix(lm.fit)[,-1])
new.baseball$salary = baseball$salary
```

\newpage

Now that we have completed the feature creation process, the next step is to analyze the data itself. 

Firstly, I'll look at the the structure of the data itself and how the different variables are associated with each other. Since there are a lot of explanatory variables within the data, I will select a few key variables I believe to be the most influential in the model and investigate the structure.

**Note:**
- `G.x` = Position played at specified position
- `InnOut` = Time played in the field expressed as outs
- `PO` = Putouts
- `E` = Errors
- `CAB` = Career at bats
- `CR` = Career runs
- `CRBI` = Career runs batted in

```{r}
pairs(salary ~ G.x + InnOuts + PO + E + CAB + CR + CRBI, data = new.baseball)
```

From observing the paired structures of data it is evident that some features are uncorrelated whereas others are strongly correlated. However, this is mostly expected as certain features relate to one another. For example, a player's career at bats would be associated with his career runs or career runs batted in since all tie into a players capability of scoring bases.

This indicates a possible issue in inference of coefficients through linear modeling since the standard error calculation will be grossly inflated.

Next, I'd like to look into whether the data is distributed normally as per an assumption of guassian distributed errors in linear modelling. 

```{r}
ggplot(data = new.baseball, aes(x = salary)) + geom_histogram(bins = 40)
```

The histogram above shows that the observed outcome values are not distributed normally at all. Hence, some sort of transformation of the data is necessary in order to use linear modelling.

```{r}
ggplot(data = new.baseball, aes(x = log(salary))) + geom_histogram(bins = 40)
```

\newpage

# Data Analysis 

### 1)

```{r}
lm(log(salary) ~ yearsneg.contract +
     yearsneg.salary + 
     log(1+CR) + 
     yearsneg.contract*log(1+CR) + 
     yearsneg.salary*log(1+CR), 
   data = new.baseball)
```


























